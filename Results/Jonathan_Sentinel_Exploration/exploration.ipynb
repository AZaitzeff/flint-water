{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What conclusions can we draw from the Sentinel sites?\n",
    "\n",
    "## Rick Snyder's tweet\n",
    "\n",
    "On April 22nd, Governer Rick Snyder posted [this now-deleted tweet](https://mobile.twitter.com/onetoughnerd/status/723614869400866816/photo/1) which showed a graph of some results from the [Flint Sentinel testing sites](http://michiganradio.org/post/sentinel-teams-monitoring-water-400-flint-homes). The graph showed a promising upward trend in Flint's water safety.\n",
    "\n",
    "Here's a screenshot of the tweet in question:\n",
    "\n",
    "<img src=\"tweet_cropped.png\">\n",
    "\n",
    "## A few minutes later, the tweet was deleted. Why?\n",
    "\n",
    "Besides some of the obvious issues with the chart, like \"particles per lead\" and the misaligned axes, there may have been some deeper methodological issues with this chart that caused @onetoughnerd to delete it. However, if the percentage of Sentinel sites below the EPA action level of 15 PPB actually is steadily increasing, this is good news! All of the sentinel data is freely available online, so we can check whether this is really the case. Using the sentinel data, we can recreate Governor Snyder's chart, and from there, we'll hopefully be able to confirm or deny what he was trying to prove.\n",
    "\n",
    "# Recreating Snyder's Tweet\n",
    "\n",
    "## First, some initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and join the Sentinel data\n",
    "\n",
    "All of this data is publicly available on the [Flint Water website](http://www.michigan.gov/flintwater/) and was downloaded on May 1st."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_1 = pd.read_excel('data/public/Sentinel_Data_Set_1A-B_515890_7.xlsx')\n",
    "df_2 = pd.read_excel('data/public/Sentinel_Data_Set_1A-B_Rnd_2_517916_7.xlsx')\n",
    "df_3 = pd.read_excel('data/public/Sentinel_Data_Round_3_521415_7.xlsx')\n",
    "df_4 = pd.read_excel('data/public/Sentinel_Data_Round_4_521993_7.xlsx')\n",
    "\n",
    "df_all = pd.concat([df_1, df_2, df_3, df_4], axis = 0)\n",
    "df_all = df_all.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group by dates\n",
    "\n",
    "df_all['Date']=df_all['Date_Submittted']\n",
    "\n",
    "def group_fn(idx):\n",
    "    x = idx['Date']\n",
    "    if x < np.datetime64('2016-02-16'):\n",
    "        return 0\n",
    "    if x < np.datetime64('2016-02-23'):\n",
    "        return 1\n",
    "    if x < np.datetime64('2016-03-02'):\n",
    "        return 2\n",
    "    if x < np.datetime64('2016-03-30'):\n",
    "        return 3\n",
    "    if x < np.datetime64('2016-04-14'):\n",
    "        return 4\n",
    "    return 5\n",
    "\n",
    "\n",
    "df_all['Group'] = df_all.apply(group_fn, axis = 1)\n",
    "gb = df_all.groupby('Group', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the percentage of tests below the action level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percent_below_action_level(x):\n",
    "    return np.mean(x<15)\n",
    "\n",
    "\n",
    "x = ['February 22', 'March 1', 'March 29', 'April 14']\n",
    "y = gb.agg(percent_below_action_level)['Result_Lead_(PPB)'].values\n",
    "rick = [.891, .913, .921, .927]\n",
    "\n",
    "plt.plot(rick, 'g')\n",
    "plt.plot(y, 'b')\n",
    "\n",
    "plt.title('Percentage of samples with lead levels below 15 ppb')\n",
    "plt.ylabel('Percentage of samples < 15 ppb')\n",
    "plt.xlabel('Samples taken on or before')\n",
    "plt.xticks(range(4), x)\n",
    "plt.legend([\"Rick Snyder's Tweet\", 'Sentinel Data'], loc=4)\n",
    "plt.savefig(\"out/pct_samples_below_15ppb.png\", dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's our result, compared to Governor Snyder's tweet:\n",
    "\n",
    "<img src='out/pct_samples_below_15ppb.png', style=\"width:500px;\"/>\n",
    "\n",
    "Cool, so the numbers mostly match up. From this plot, the trend seems to be clearly upwards. But as a wise statistics professor once told me, **_Never trust a graph without error bars._** When we compute aggregate statistics over a small number of samples, there's always some uncertainty in the estimates we receive. It is therefore possible that the real distribution of the sentinel data doesn't actually follow a clear upward trend, but that the trend we see here is just due to random chance. Without a more in-depth analysis, we cannot draw any definite conclusions. Let's explore this further.\n",
    "\n",
    "# First, lets recreate the same plot, but with error bars\n",
    "\n",
    "In order to get error bars, we take 1000 bootstrap samples and plot the 95% confidence interval around each of our estimates. This gives us an idea of how wide the distribution is. Essentially, the confidence interval estimates a range for which we can say the following: *if we were to resample the data many times, the percentage of samples below 15 PPB would fall in this range 95% of the time*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(y = 'Result_Lead_(PPB)', x = 'Group', data=df_all,\n",
    "               estimator = lambda x: (x<15).mean(), n_boot=1000, ci=95)\n",
    "\n",
    "plt.title('Percentage of samples with lead levels below 15 ppb')\n",
    "plt.grid(b = True, axis='x', which='major')\n",
    "plt.ylabel('Percentage of samples < 15 ppb')\n",
    "plt.xlabel('Samples taken on or before')\n",
    "plt.xticks(range(4), x)\n",
    "plt.savefig('out/pct_samples_below_15ppb_errorbars.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error bars give us a clearer picture of the distribution\n",
    "\n",
    "<img src='out/pct_samples_below_15ppb_errorbars.png', style=\"width:500px;\"/>\n",
    "\n",
    "With such wide confidence intervals, we can't conclude much about the trend of the water safety. It's very much possible that this upward trend is due to nothing more than random chance.\n",
    "\n",
    "# Do other statistics show positive trends?\n",
    "\n",
    "Although our results so far have been inconclusive, we can look at other statistics from the sentinel data and check for positive trends. If we consistently see positive trends, we can more safely conclude that the situation in Flint is improving.\n",
    "\n",
    "## 90th percentile of lead readings\n",
    "\n",
    "Another statistic relevant to water quality is the 90th percentile of the distribution of lead measurements. This tells us roughly how high the lead readings are *for the 10% of houses with the highest readings.* Again, we can easily plot the 90th percentile of the lead readings for each round of sentinel tests, with a 95% confidence interval drawn around the estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(y = 'Result_Lead_(PPB)', x = 'Group', data=df_all,\n",
    "               estimator = lambda x: np.percentile(x, 90), n_boot=1000, ci = 95)\n",
    "p1, = plt.plot(range(-1,5), [15]*6, 'r--')\n",
    "\n",
    "plt.title('90th Percentile of Lead Readings')\n",
    "plt.grid(b = True, axis='x', which='major')\n",
    "plt.ylabel('Lead (PPB)')\n",
    "plt.xlabel('Samples taken on or before')\n",
    "plt.xticks(range(4), x)\n",
    "plt.legend([p1], ['Federal Action Level (15 PPB)'])\n",
    "plt.savefig('out/pctile_90.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src='out/pctile_90.png', style=\"width:500px;\"/>\n",
    "\n",
    "Again, we see a positive trend (down is good in this case!), and even more interesting is the fact that the confidence interval has moved below the federal action level of 15 PPB. We can now safely conclude that, among the sentinel sites, 90% of homes have lead readings below 15 PPB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are these trends the same in the residential data?\n",
    "\n",
    "Note that our previous analysis has only considered data collected from the sentinel sites. The water samples taken from the sentinel sites are controlled and reliable, but comprise only a small number of locations in the city. Although the sample size is small, this sample is meant to be representative of the entire city. If this is the case, we would hope to see the same trends in the voluntary tests submitted by residents. However, it is important to note that the voluntary residential test data is particularly subject to certain biases. In particular, residents are permitted to sample the lead readings from their homes as many times as they want, and at irregular intervals. Those who have tested their water before may be more likely to test again if they received high lead readings. We proceed with these potential biases in mind.\n",
    "\n",
    "## First, load and parse the residential data\n",
    "\n",
    "This data is also available via the [Flint Water website](http://www.michigan.gov/flintwater/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the residential test data\n",
    "x = ['February 22', 'March 1', 'March 29', 'April 14']\n",
    "df_all['Log_Lead'] = np.log(df_all['Result_Lead_(PPB)']+1)\n",
    "\n",
    "# Combine sentinel and residential\n",
    "df_residential = pd.read_csv('data/residential_test_data.csv',\n",
    "                             parse_dates=[1])\n",
    "df_residential = pd.DataFrame(\n",
    "    {'Lead': df_residential['Lead (ppb)'],\n",
    "     'Date': df_residential['Date Submitted'],\n",
    "     'Source': ['Residential']*len(df_residential)})\n",
    "\n",
    "df_sentinel = pd.DataFrame(\n",
    "    {'Lead': df_all['Result_Lead_(PPB)'],\n",
    "     'Date': df_all['Date_Submittted'],\n",
    "     'Source': ['Sentinel']*len(df_all)})\n",
    "\n",
    "df_final = pd.concat([df_residential, df_sentinel], axis = 0)\n",
    "\n",
    "df_final['Group'] = df_final.apply(group_fn, axis=1)\n",
    "df_final['Log_Lead'] = np.log(df_final['Lead'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 90th percentile of lead readings, revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the plots\n",
    "sent = sns.factorplot(x = 'Group', y = 'Lead', hue = 'Source', hue_order=['Sentinel', 'Residential'],\n",
    "                      estimator = lambda x: np.percentile(x, 90), data=df_final,\n",
    "                      n_boot=1000)\n",
    "\n",
    "p1, = plt.plot(range(-1,6), [15]*7, 'r--')\n",
    "\n",
    "x = ['February 15', 'February 22', 'March 1', 'March 29', 'April 14']\n",
    "\n",
    "plt.title('90th Percentile of Lead Readings')\n",
    "plt.grid(b = True, axis='x', which='major')\n",
    "plt.ylabel('Lead (PPB)')\n",
    "plt.xlabel('Samples taken on or before')\n",
    "plt.xticks(range(5), x)\n",
    "plt.legend([p1], ['Federal Action Level (15 PPB)'])\n",
    "plt.savefig('out/res_vs_sent.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"out/res_vs_sent.png\", style=\"width:500px;\"/>\n",
    "\n",
    "\n",
    "Not only do these two trend lines look very different from one another, it seems like the downward trend is even less clear in the residential data than it was in the sentinel data. In addition, since the confidence interval from the residential data includes the federal action level of 15 ppb, we *are unable to conclude that 90% of the homes in Flint have lead below 15 ppb*.\n",
    "\n",
    "# Conclusions\n",
    "\n",
    "We can safely say that _**among the sentinel sites** we have sufficient evidence to conlude that the 90th percentile of lead readings is below 15 ppb_. However, _we fail to draw the same conclusion using the voluntary residential lead samples._\n",
    "\n",
    "So was Governor Snyder's tweet misleading? In a way, yes, since it failed to use proper statistical methodology to give a full picture of the data it was representing. However, the conclusion suggested by Governor Snyder's graph can be reached through other means, as we've shown here. The sentinel sites have, in fact, shown improvement over the past few months."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
